created an environment 

```bash
conda create -n wineq python=3.7 -y
```

activate 

```bash
conda activate wineq
```

create a requirement.txt file and write all important packages in it to install, then run the command
```bash
pip install -r requirements.txt
```

Create a template.py file, inside that create directory structures and mention name of the files what are needed. 
while creating the directory for git initialization create .gitkeep file in every directory.

Now the files we needed is dvc.yaml, params.yaml .gitignore and inside src create __init__.py so yhat we can use src
as python package. After doing all in terminal run 
```bash
python template.py
```

create one more folder data_given in which we will put the wine quality data and it will be acting as a remote resource
for us. Put the winequality.csv data in the data_given folder.
```bash
mkdir data_given
```

Now initiate the git and dvc. run these commands in terminal
```bash
git init
dvc init
dvc add data_given/winequality.csv
git add .
git commit -m "First Commit"
```

Now create a github repo. and run the commands
```bash
git remote add origin <repo link>
```
```bash
git branch -M main
```
```bash
git push -u origin main
```

 * Now we will start developing the main part. In params.yaml file write base, data_source, load_data, split_data, 
estimators, model_dir, reports and all its components.
 * The interpretation will be something like this : we take the data from data_source and put in load_data then we 
will do split_data then estimators for models and their parameters and defined model directory for saving the models.
 * Inside dvc.yaml file we will mention the stages later. 

#### Now starting the first stage:
 * inside src create a file get_data.py 
 * it will just read the params, process it and return  the dataframe and we will call it from other custom functions.
 * inside src create load_data.py for copying or moving data from data_given to data\raw folder for further process
 * after this after changing the load_data.py in dvc.yaml we can write the stages like load_data, command, dependencies 
   and outputs generated by load_data.py

now we will run dvc reproduce command and it will run all the stages mentioned till now and it will create a dvc.lock file.
it keeps track of all the chages made in the stages.
```bash
dvc repro
```
#### Now our stage 1 complete
#### Now second stage 
* create a file split_data.py inside src it will split the raw into train and test data and move it to data\processed.
* now write that split_data stages in dvc.yaml file i.e. command dependencies and outputs. 
* run the dvc repro command
* save the chages and push it in github













